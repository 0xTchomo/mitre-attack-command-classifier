# ğŸ›¡ï¸ MITRE ATT&CK Command Classification using ML & Deep Learning

**Python 3.8+** | **TensorFlow 2.0+** | **scikit-learn 1.0+** | **MIT License**

> **From raw command-line telemetry to actionable ATT&CK technique classification**

This project investigates how **command-line process titles (`proctitle`)** can be automatically classified into **MITRE ATT&CK techniques** using both **Machine Learning (ML)** and **Deep Learning (DL)** approaches.

The focus extends beyond model performance to address **realistic threat modeling**, **data imbalance handling**, and **domain-aware feature engineering**â€”critical components for operational cybersecurity systems.

---

## ğŸ¯ Motivation

Command-line executions are among the strongest indicators of attacker activity on compromised hosts, directly exposing:
- ğŸ” **Reconnaissance** patterns
- â†”ï¸ **Lateral movement** behaviors
- ğŸ”’ **Persistence** mechanisms
- âš¡ **Execution** techniques

### The Challenge

Command data presents unique difficulties:
- Commands are **short and noisy**
- Semantics depend on **arguments, flags, paths, and IPs**
- The **same command** may correspond to different ATT&CK techniques
- Datasets are naturally **imbalanced** and frequency-driven

### Our Solution

This project addresses these challenges through:
- âœ… Careful exploratory data analysis
- âš–ï¸ Frequency-aware learning with sample weighting
- ğŸ”§ Custom tokenization for cyber artifacts
- ğŸ“Š Comparative study between ML and DL models

---

## ğŸ“Š Dataset Description

### Dataset Origin

The dataset originates from the **Casino Limit Capture-The-Flag (CTF)** challengeâ€”a realistic offensive security scenario where multiple attacking teams operated against a defended infrastructure.

**Key aspects:**
- âœ”ï¸ Attacker activity was fully monitored
- âœ”ï¸ All executed commands were collected from system logs
- âœ”ï¸ Each command was annotated with **MITRE ATT&CK techniques**

**References:**
- [Casino Limit Challenge](https://casinolimit.inria.fr/challenge.html)
- [Dataset Paper](https://inria.hal.science/hal-05224264)

---

### Raw Data Characteristics

Each row represents an **observed command execution pattern** with the following fields:

| Field | Description |
|-------|-------------|
| `proctitle` | The full command-line string as executed |
| `technique` | Original MITRE ATT&CK technique label |
| `technique_grouped` | Consolidated ATT&CK technique for modeling |
| `count` | Number of times this `(proctitle, technique)` pair appeared |

> **âš ï¸ Important:** The dataset does **not** represent unique commands only. Execution frequency (`count`) is a first-class signal explicitly used during training.

---

### Dataset Statistics

| Metric | Value |
|--------|-------|
| Initial ATT&CK techniques | **67** |
| Final techniques after consolidation | **37** |
| Unique command strings | **~100** |
| Total observations | **70,992** |
| Class imbalance | **High** (reflects real attacker behavior) |

**Distribution highlights:**
- `T1082: System Information Discovery` â†’ 355,723 occurrences (85.2%)
- `T1595: Active Scanning` â†’ 12,321 occurrences (3.0%)
- `Normal` â†’ 5,105 occurrences (1.2%)
- Rare techniques grouped into `Z999: Other Low-Frequency Techniques`

---

### Technique Consolidation Strategy

To ensure meaningful training and stratified splits, rare techniques are grouped into:

**`Z999 â€” Other Low-Frequency Techniques`**

This grouping:
- âœ… Prevents extreme overfitting on rare classes
- âœ… Avoids empty classes in validation/test splits
- âœ… Preserves semantic interpretability

> **ğŸ“ Note:** Apparent duplicates after grouping are **expected and intentional**â€”they represent different techniques mapping to the same command or frequency aggregation, not data leakage.

---

### Dataset Availability

```
data/
â”œâ”€â”€ raw/                  # Full processed dataset
â”œâ”€â”€ sample/               # Lightweight CSV for quick inspection
â””â”€â”€ README.md            # Additional dataset documentation
```

---

## ğŸ”¬ Methodology Overview

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

**ğŸ““ Notebook:** `notebooks/01_eda.ipynb`

**Objectives:**
- Inspect dataset structure and types
- Analyze technique distributions
- Understand the semantic meaning of the `count` column
- Validate the need for frequency-weighted learning
- Consolidate `(proctitle, technique_grouped)` pairs by summing counts

**ğŸ’¡ Key Insight:**
> In cybersecurity telemetry, frequency is part of the signal, not noise.

---

### 2ï¸âƒ£ Machine Learning Baseline (TF-IDF + Logistic Regression)

**ğŸ““ Notebook:** `notebooks/02_ml_lr.ipynb`

#### Feature Engineering

Commands are vectorized using **TF-IDF (unigrams + bigrams)** with a custom token pattern that preserves:
- ğŸŒ IP addresses and ports (`10.35.108.10:22`)
- ğŸ”— URLs (`http://malicious.com/exploit.sh`)
- ğŸ“ Filesystem paths (`/etc/passwd`, `/tmp/file[1].txt`)
- ğŸš© Command flags (`--color=auto`, `-la`)
- ğŸ’² Environment variables (`$HOME`, `${PATH}`)

**Example tokenization:**
```
cat /etc/passwd              â†’ ['cat', '/etc/passwd']
ssh user@10.35.108.10:22     â†’ ['ssh', 'user@10.35.108.10', '22']
wget http://malicious.com    â†’ ['wget', 'http://malicious.com']
```

#### Training Strategy

- **Split:** 60% train / 20% validation / 20% test (stratified)
- **Sample weights:** Execution count from the `count` column
- **Evaluation:** Weighted accuracy and F1-score
- **Hyperparameter tuning:** GridSearchCV with 3-fold CV

#### Results

| Model | Accuracy | F1-Score (Weighted) |
|-------|----------|---------------------|
| Default LR | 70.84% | 79.08% |
| **Optimized LR** | **85.02%** | **83.58%** |

**Best hyperparameters:**
- `C=10`
- `penalty='l2'`
- `solver='lbfgs'`
- `class_weight=None`
- `max_iter=1000`

**Performance characteristics:**
- âœ… Strong and stable weighted performance
- âœ… High accuracy on frequent techniques
- âœ… High interpretability and low computational cost
- âš ï¸ Confusions mainly between semantically close ATT&CK techniques

**Confusion Matrix:**

![Confusion Matrix - Logistic Regression](images/confusion_matrix_lr.png)

*The confusion matrix shows strong diagonal performance, indicating accurate classification across most ATT&CK techniques. The model achieves 12,070 correct predictions out of 14,197 total test samples (85.02% accuracy).*

This makes the ML model a **robust baseline** for operational environments.

---

### 3ï¸âƒ£ Deep Learning Baseline (Tokenizer + LSTM)

**ğŸ““ Notebook:** `notebooks/03_dl_lstm.ipynb`

#### Preprocessing

**Tokenizer configuration:**
- `num_words=5000`
- `oov_token="<unk>"`
- `lower=True`

**Sequence preprocessing:**
- `MAX_SEQUENCE_LENGTH = 20`
- `pad_sequences(..., padding='post', truncating='post')`

**Label handling:**
- LabelEncoder + one-hot encoding (`to_categorical`)
- Prevents false ordinal relationships between class indices
- Matches softmax output format for proper training

#### Model Architecture

```python
Sequential([
    Embedding(VOCAB_SIZE, 100, input_length=20),
    LSTM(64),
    Dropout(0.5),
    Dense(37, activation='softmax')
])
```

**Training configuration:**
- Optimizer: `adam`
- Loss: `categorical_crossentropy`
- Early stopping on `val_loss` (patience=3, restore_best_weights)
- Epochs: 10, Batch size: 32
- Sample weights applied

#### Results

| Metric | Value |
|--------|-------|
| **Accuracy** | **83.45%** |
| **F1-Score (Weighted)** | **78.54%** |

**Classification Report:**

```
                                              precision  recall  f1-score  support
T1082: System Information Discovery              0.94     1.00      0.97    10555
T1595: Active Scanning                           0.49     0.97      0.66     1049
T1125: Video Capture                             0.52     0.95      0.67      110
T1572: Protocol Tunneling                        0.50     0.66      0.57       61
T1046: Network Service Discovery                 0.51     0.33      0.40      171
T1105: Ingress Tool Transfer                     0.18     0.73      0.30      132
...

accuracy                                                           0.83    14197
macro avg                                        0.09     0.13      0.10    14197
weighted avg                                     0.75     0.83      0.79    14197
```

*The LSTM model shows strong performance on dominant classes like T1082 (97% F1-score) but struggles with minority classes, reflected in the lower macro-average F1 (0.10) compared to weighted average (0.79).*

---

## ğŸ“ˆ ML vs DL Comparison

### Performance Summary

| Approach | Accuracy | Weighted F1 | Training Time | Interpretability |
|----------|----------|-------------|---------------|------------------|
| **Optimized LR** | **85.02%** | **83.58%** | Fast | High |
| LSTM Baseline | 83.45% | 78.54% | Moderate | Low |

### Detailed Classification Reports Comparison

#### Logistic Regression (Optimized with Custom Pattern)

```
                                              precision  recall  f1-score  support
T1082: System Information Discovery              0.95     0.99      0.97    10555
T1595: Active Scanning                           0.44     0.55      0.49     1049
T1018: Remote System Discovery                   0.41     0.30      0.35      976
Normal                                           0.37     0.17      0.24      342
T1046: Network Service Discovery                 0.52     0.53      0.52      171
T1083: File and Directory Discovery              0.76     0.66      0.70      116
T1125: Video Capture                             0.95     0.98      0.96      110
T1021: Remote Services                           0.71     0.78      0.75       73
...

accuracy                                                           0.85    14197
weighted avg                                     0.83     0.85      0.84    14197
```

#### LSTM Baseline

```
                                              precision  recall  f1-score  support
T1082: System Information Discovery              0.94     1.00      0.97    10555
T1595: Active Scanning                           0.49     0.97      0.66     1049
T1125: Video Capture                             0.52     0.95      0.67      110
T1572: Protocol Tunneling                        0.50     0.66      0.57       61
T1046: Network Service Discovery                 0.51     0.33      0.40      171
Many minority classes                            0.00     0.00      0.00      ...
...

accuracy                                                           0.83    14197
weighted avg                                     0.75     0.83      0.79    14197
```

### Key Findings

**Machine Learning (Logistic Regression) wins for this dataset:**
- âœ… Domain-aware feature engineering (custom token pattern) is extremely effective
- âœ… Best overall weighted F1-score
- âœ… Fast training and inference
- âœ… Highly interpretable for security analysts
- âœ… Robust to class imbalance with sample weighting

**Deep Learning (LSTM) performance:**
- âœ… Competitive accuracy
- âš ï¸ Lower weighted F1, likely due to:
  - Heavy class imbalance and frequency effects
  - Limited dataset size for deep semantic generalization
  - Higher sensitivity to hyperparameters
- âš ï¸ Requires more computational resources
- âš ï¸ Less interpretable for operational use

---

## ğŸš€ Reproducibility

### Installation

**For Machine Learning:**
```bash
pip install -r requirements.txt
```

**For Deep Learning:**
> TensorFlow on Windows typically requires Python 3.10â€“3.11

```bash
pip install -r requirements-dl.txt
```

### Run Notebooks

```bash
jupyter notebook notebooks/
```

**Recommended order:**
1. `01_eda.ipynb` â€” Exploratory Data Analysis
2. `02_ml_lr.ipynb` â€” Machine Learning Baseline
3. `03_dl_lstm.ipynb` â€” Deep Learning Baseline

---

## ğŸ“ Project Structure

```
mitre-attack-command-classifier/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                    # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_ml_lr.ipynb                  # ML: Logistic Regression
â”‚   â””â”€â”€ 03_dl_lstm.ipynb                # DL: LSTM
â”‚
â”œâ”€â”€ command_classifier/
â”‚   â”œâ”€â”€ train_lr.py                     # LR training script
â”‚   â”œâ”€â”€ train_lstm.py                   # LSTM training script
â”‚   â”œâ”€â”€ predict.py                      # Inference script
â”‚   â”œâ”€â”€ common.py                       # Shared utilities
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                            # Full dataset
â”‚   â”œâ”€â”€ sample/                         # Sample dataset
â”‚   â””â”€â”€ README.md                       # Dataset documentation
â”‚
â”œâ”€â”€ requirements.txt                    # ML dependencies
â”œâ”€â”€ requirements-dl.txt                 # DL dependencies
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš ï¸ Limitations and Future Work

### Current Limitations

- âŒ Commands analyzed independently (no temporal correlation)
- âŒ No host-level or user-level context
- âŒ Deep learning constrained by dataset size
- âŒ Limited to 37 consolidated ATT&CK techniques

### Future Directions

- ğŸ”„ **Command sequence modeling:** Capture temporal attack patterns
- ğŸ”— **Attack chain reconstruction:** Link commands into kill chains
- ğŸ”Œ **SIEM/EDR integration:** Real-time threat detection pipelines
- ğŸ‘¤ **Human-in-the-loop validation:** Active learning with analyst feedback
- ğŸŒ **Multi-host correlation:** Detect distributed attacks
- ğŸ“š **Transfer learning:** Leverage pre-trained models on cybersecurity corpora

---

## ğŸ“ Academic Context

This project was originally developed as part of an advanced course on **AI-based threat detection** at **TÃ©lÃ©com Paris**, and was later **refactored and extended** into a standalone portfolio project suitable for professional and research evaluation.

---

## ğŸ“œ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ‘¤ Author

**Thierry Armel Tchomo Kombou**  
Cybersecurity & AI Engineering  
TÃ©lÃ©com Paris

**GitHub:** [github.com/0xTchomo](https://github.com/0xTchomo)  
**LinkedIn:** [Connect with me](https://www.linkedin.com/in/thierry-armel-tchomo-kombou)

---

## ğŸŒŸ Key Takeaways

1. **Domain expertise matters:** Custom tokenization for cybersecurity artifacts significantly improves performance
2. **Simple models can be powerful:** Logistic Regression with TF-IDF outperforms LSTM on this dataset
3. **Frequency is signal:** Proper handling of execution counts improves weighted metrics
4. **Class imbalance is real:** Stratified splitting and sample weighting are essential
5. **Interpretability is valuable:** For operational security, model transparency is crucial

---

## ğŸ“š References

- [MITRE ATT&CK Framework](https://attack.mitre.org/)
- [Casino Limit CTF Challenge](https://casinolimit.inria.fr/challenge.html)
- [Dataset Paper (HAL)](https://inria.hal.science/hal-05224264)

---

<p align="center">
  <i>â­ If you find this project useful, please consider giving it a star!</i>
</p>
